#cell1
!apt-get update -qq && apt-get install -y openjdk-11-jdk-headless -qq
import os
os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-11-openjdk-amd64'

!pip install -q pyspark plotly pandas matplotlib
print("Installed Java + PySpark + plotting libs")

#cell2
from google.colab import files
print("Click and upload your dataset.csv (Kaggle file) when prompted.")
uploaded = files.upload()

#cell3
from pyspark.sql import SparkSession
spark = SparkSession.builder \
    .master('local[*]') \
    .appName('HigherStudiesAnalysis') \
    .getOrCreate()
print("Spark version:", spark.version)

#cell4
csv_path = "dataset.csv"
print("Using CSV path:", csv_path)

#cell5
df = spark.read.option('header', True).option('inferSchema', True).csv(csv_path)

print("Rows:", df.count(), "Columns:", len(df.columns))
print("Column names:", df.columns)

df.printSchema()
df.show(8, truncate=False)

#cell6
country_col = "Region_of_Study"
level_col   = "Education_Level"
course_col  = "Field_of_Study"
tuition_col = "Salary"             # proxy for cost/outcome
employ_col  = "Employment_Status"

#cell7
from pyspark.sql.functions import when, col

# Graduate flag: 1 if Master's or PhD, else 0
df = df.withColumn('is_graduate', when(col(level_col).rlike("(?i)master|phd"), 1).otherwise(0))

# Employed flag: 1 if Employment_Status is Employed, else 0
df = df.withColumn('is_employed', when(col(employ_col).rlike("(?i)employed"), 1).otherwise(0))

# Show sample
df.select(country_col, level_col, course_col, tuition_col, employ_col, 'is_graduate', 'is_employed').show(8, truncate=False)

#cell8
# 1️⃣ Top regions by student count
df.groupBy(country_col).count().orderBy('count', ascending=False).show(10)

# 2️⃣ Average salary by region
df.groupBy(country_col).avg(tuition_col).withColumnRenamed(f"avg({tuition_col})", "avg_salary")\
  .orderBy('avg_salary', ascending=False).show(10)

# 3️⃣ Average salary by course/field
df.groupBy(course_col).avg(tuition_col).withColumnRenamed(f"avg({tuition_col})", "avg_salary_by_course")\
  .orderBy('avg_salary_by_course', ascending=False).show(10)

# 4️⃣ Employment rate by region
df.groupBy(country_col).avg('is_employed').withColumnRenamed("avg(is_employed)", "employment_rate")\
  .orderBy('employment_rate', ascending=False).show(10)

#cell9
# Bar: Student counts by region
region_counts = df.groupBy(country_col).count().orderBy('count', ascending=False).limit(15).toPandas()
fig = px.bar(region_counts, x=country_col, y='count', title='Top Regions by Student Count')
fig.show()

# Bar: Average salary by course/field
avg_course = df.groupBy(course_col).avg(tuition_col).withColumnRenamed(f"avg({tuition_col})", "avg_salary")\
               .orderBy('avg_salary', ascending=False).limit(20).toPandas()
fig = px.bar(avg_course, x=course_col, y='avg_salary', title='Average Salary by Course/Field')
fig.show()

# Pie: Employment status distribution
emp_dist = df.groupBy(employ_col).count().toPandas()
fig = px.pie(emp_dist, names=employ_col, values='count', title='Employment Status Distribution')
fig.show()

# Bar: Average salary by region
avg_region = df.groupBy(country_col).avg(tuition_col).withColumnRenamed(f"avg({tuition_col})", "avg_salary")\
               .orderBy('avg_salary', ascending=False).limit(15).toPandas()
fig = px.bar(avg_region, x=country_col, y='avg_salary', title='Average Salary by Region')
fig.show()

#cell10
out_path = '/content/cleaned_higher_studies.csv'
df.limit(100000).toPandas().to_csv(out_path, index=False)  # limit to avoid memory issues
from google.colab import files
files.download(out_path)

#cell11
spark.stop()
print("Spark session stopped. Done!")

#cell12
import plotly.express as px
from google.colab import files

# 1️⃣ Bar: Top regions by student count
region_counts = df.groupBy(country_col).count().orderBy('count', ascending=False).limit(15).toPandas()
fig1 = px.bar(region_counts, x=country_col, y='count', title='Top Regions by Student Count')
fig1.write_html("/content/top_regions_student_count.html")
files.download("/content/top_regions_student_count.html")

# 2️⃣ Bar: Average salary by course/field
avg_course = df.groupBy(course_col).avg(tuition_col).withColumnRenamed(f"avg({tuition_col})", "avg_salary")\
               .orderBy('avg_salary', ascending=False).limit(20).toPandas()
fig2 = px.bar(avg_course, x=course_col, y='avg_salary', title='Average Salary by Course/Field')
fig2.write_html("/content/avg_salary_by_course.html")
files.download("/content/avg_salary_by_course.html")

# 3️⃣ Pie: Employment status distribution
emp_dist = df.groupBy(employ_col).count().toPandas()
fig3 = px.pie(emp_dist, names=employ_col, values='count', title='Employment Status Distribution')
fig3.write_html("/content/employment_status_distribution.html")
files.download("/content/employment_status_distribution.html")

# 4️⃣ Bar: Average salary by region
avg_region = df.groupBy(country_col).avg(tuition_col).withColumnRenamed(f"avg({tuition_col})", "avg_salary")\
               .orderBy('avg_salary', ascending=False).limit(15).toPandas()
fig4 = px.bar(avg_region, x=country_col, y='avg_salary', title='Average Salary by Region')
fig4.write_html("/content/avg_salary_by_region.html")
files.download("/content/avg_salary_by_region.html")

# GPA by Education Level
avg_gpa = df.groupBy(level_col).avg('GPA').withColumnRenamed('avg(GPA)', 'avg_GPA').toPandas()
fig5 = px.bar(avg_gpa, x=level_col, y='avg_GPA', title='Average GPA by Education Level')
fig5.write_html("/content/avg_gpa_by_education.html")
files.download("/content/avg_gpa_by_education.html")

# Internship vs Employment Rate
internship_emp = df.groupBy('Internship_Experience').avg('is_employed').withColumnRenamed('avg(is_employed)', 'employment_rate').toPandas()
fig6 = px.bar(internship_emp, x='Internship_Experience', y='employment_rate', title='Employment Rate by Internship Experience')
fig6.write_html("/content/employment_rate_by_internship.html")
files.download("/content/employment_rate_by_internship.html")


